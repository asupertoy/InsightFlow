from langchain_core.messages import SystemMessage, HumanMessage
from ..state import AgentState
from ..llm.router import get_model_router
from ..utils.parser import strip_thinking_tokens
from .prompts import REVIEWER_SYSTEM_PROMPT, REVIEWER_USER_TEMPLATE

def reviewer_node(state: AgentState):
    """
    Reviewer Node (å®¡æŸ¥èŠ‚ç‚¹)
    
    åŠŸèƒ½ï¼š
    1. æ¥æ”¶ `draft_report` å’ŒåŸå§‹ `query`ï¼Œä»¥åŠ `revision_count`ã€‚
    2. åˆ¤æ–­æ˜¯å¦æ»¡è¶³ç”¨æˆ·éœ€æ±‚ã€‚
    3. å¦‚æœæ»¡è¶³ï¼Œæ ‡è®° `review_status="approve"`ã€‚
    4. å¦‚æœä¸æ»¡è¶³ä¸”å¯ä»¥æ”¹è¿›ï¼Œæ ‡è®° `review_status="reject"` å¹¶ç»™å‡ºå…·ä½“ `feedback`ã€‚
    5. è‡ªåŠ¨å¢åŠ  `revision_count`ã€‚
    """
    print("--- ğŸ§ Reviewer Node: Checking Results ---")
    
    query = state.get("query", "")
    draft_report = state.get("draft_report", "")
    revision_count = state.get("revision_count", 0) + 1
    
    if int(revision_count) >= 3:
        print("Maximum revisions reached. Forcing approval.")
        return {
            "review_status": "approve",
            "feedback": "Max revisions reached. Finalizing report.",
            "revision_count": revision_count
        }
        
    if not draft_report:
        print("No report drafted yet. Approving empty (likely internal error or incomplete plan).")
        # å¦‚æœæ²¡æœ‰æŠ¥å‘Šï¼Œå¯èƒ½è¿˜åœ¨ Planner é˜¶æ®µï¼Œä¸åº”è¯¥èµ°åˆ° reviewï¼Œé™¤é Planner å®Œäº†ä½† Writer æ²¡äº§å‡º
        # ç¨³å¦¥èµ·è§ï¼Œæˆ‘ä»¬è®¤ä¸ºå¦‚æœä¸å®Œæ•´åˆ™ä¸éœ€è¦ reviewï¼Œç›´æ¥é€šè¿‡ï¼ˆæˆ–è€…å›æ»šï¼‰
        # è¿™é‡Œå‡è®¾ Writer åªæœ‰æœ€åæ‰äº§ draft
        return {
            "review_status": "approve", # Force approval to end loop if empty
            "revision_count": revision_count
        }

    # è·å–å®¡æŸ¥æ¨¡å‹ (Reasoning / High Context)
    llm = get_model_router().get_model("reviewing")

    system_prompt = REVIEWER_SYSTEM_PROMPT

    user_prompt = REVIEWER_USER_TEMPLATE.format(
        query=query,
        draft_report=draft_report
    )

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt)
    ]
    
    try:
        response = llm.invoke(messages)
        content = strip_thinking_tokens(response.content)
        
        # ç®€å•è§£æ JSON string used reasoning model might output natural language wrapper
        # å°è¯•æ­£åˆ™æå– JSON block
        import json
        import re
        
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            result = json.loads(json_match.group())
            decision = result.get("decision", "approve").lower()
            feedback = result.get("feedback", "")
        else:
            # Fallback
            if "approve" in content.lower():
                decision = "approve"
                feedback = "Initial approval (JSON parsing failed)."
            else:
                decision = "reject" 
                feedback = content
        
    except Exception as e:
        print(f"Review failed: {e}. Defaulting to approve.")
        decision = "approve"
        feedback = f"Error during review: {e}"

    print(f"Review Decision: {decision.upper()} (Round {revision_count})")
    
    return {
        "review_status": decision,
        "feedback": feedback,
        "revision_count": revision_count, # Increment here
        # Optionally pass feedback to history
        "revision_history": [f"Round {revision_count}: {decision} - {feedback}"] # Append logic via reducer? No need, list concat in operator
    }
