import json
import os
from typing import List

from langchain_core.messages import SystemMessage, HumanMessage

from ..state import AgentState, Finding
from ..llm.router import get_model_router
from ..tools.search_tool import SearchTool
from ..tools.note_tool import NoteTool
from ..utils.parser import strip_thinking_tokens
from .prompts import RESEARCHER_SYSTEM_PROMPT_SUMMARIZER, RESEARCHER_USER_TEMPLATE_SUMMARIZER
from ..utils.logger import get_logger

logger = get_logger("researcher")

def researcher_node(state: AgentState):
    """
    Researcher Node (ç ”ç©¶å‘˜èŠ‚ç‚¹)
    
    åŠŸèƒ½ï¼š
    1. è·å–å½“å‰ plan ä¸­ current_step_index æŒ‡å‘çš„ä»»åŠ¡ã€‚
    2. ä½¿ç”¨ Tavily æ‰§è¡Œæœç´¢ (search_query)ã€‚
    3. (å¯é€‰ä½†æ¨è) ä½¿ç”¨ vLLM (fast_llm) å¯¹æœç´¢ç»“æœè¿›è¡Œé˜…è¯»å’Œæ‘˜è¦ã€‚
       - è¿™ä¸€æ­¥æ˜¯ä¸ºäº†é˜²æ­¢æŠŠå‡ åä¸ªç½‘é¡µçš„æ— å…³å†…å®¹å…¨éƒ¨å¡ç»™åé¢çš„ Writerã€‚
       - è¿™é‡Œæˆ‘ä»¬å®ç°ä¸€ä¸ªç®€åŒ–çš„ map-reduceï¼šSearch -> Raw Content -> Summaryã€‚
    4. æ›´æ–° research_findings å’Œ running_summaryã€‚
    5. æ ‡è®°æ­¥éª¤çŠ¶æ€ (Status) å’Œ last_step_successã€‚
    """
    logger.info("--- ğŸ” Researcher Node: Searching and Reading ---")
    
    plan = state.get("plan", [])
    current_index = state.get("current_step_index", 0)
    
    # è¾¹ç•Œæ£€æŸ¥
    if current_index >= len(plan):
        logger.warning("Researcher: All steps completed or index out of bounds.")
        return {"last_step_success": False}
        
    current_step = plan[current_index]
    query = current_step.get("search_query")
    description = current_step.get("description")
    
    logger.info(f"Executing Step {current_index + 1}: {description}")
    logger.info(f"Search Query: {query}")
    
    # --- 1. æ‰§è¡Œæœç´¢ ---
    try:
        # ä½¿ç”¨å°è£…å¥½çš„ SearchTool
        search_tool = SearchTool(max_results=5)
        search_results = search_tool.invoke(query)
        
        # å°†ç»“æœè½¬æ¢ä¸º Finding å¯¹è±¡åˆ—è¡¨
        new_findings: List[Finding] = []
        raw_texts = []
        
        # SearchTool å·²ç»ä¿è¯è¿”å› List[Dict] å¹¶ä¸”åŒ…å« standard keys (url, content, title)
        if search_results:
            for res in search_results:
                url = res.get("url")
                content = res.get("content")
                title = res.get("title")
                
                # ç®€å•æ¸…æ´—
                if content and len(content) > 50:
                    new_findings.append({
                        "url": url,
                        "content": content,
                        "title": title, 
                        "score": 0.8 # é»˜è®¤ç½®ä¿¡åº¦
                    })
                    raw_texts.append(f"Source ({title} - {url}): {content}")
        else:
            # å¦‚æœæœç´¢å¤±è´¥æˆ–è¿”å›ç©º
            logger.warning(f"Search warning: No results found for '{query}'")
            
    except Exception as e:
        logger.error(f"Search failed: {e}")
        # æ ‡è®°å¤±è´¥ï¼Œä½†ä¹Ÿè®¸å¯ä»¥é€šè¿‡ retry æœºåˆ¶æ¢å¤ï¼Œè¿™å°±ä½“ç°äº† last_step_success çš„ä½œç”¨
        return {
            "last_step_success": False,
            # ä¹Ÿå¯ä»¥æ›´æ–° plan é‡Œçš„ status ä¸º failed
            "plan": [
                {**step, "status": "failed"} if i == current_index else step 
                for i, step in enumerate(plan)
            ]
        }

    # --- 2. é˜…è¯»ä¸æ‘˜è¦ (Machine Reading) ---
    # å¦‚æœæ‰¾åˆ°äº†å†…å®¹ï¼Œæˆ‘ä»¬ç”¨ fast_llm (vLLM) åšä¸€ä¸ªå¿«é€Ÿæ€»ç»“
    summary = ""
    if raw_texts:
        # è·å–â€œå¿«â€æ¨¡å‹
        llm = get_model_router().get_model("summarization")
        
        # æ‹¼æ¥ä¸Šä¸‹æ–‡
        context_str = "\n\n".join(raw_texts)
        
        system_prompt = RESEARCHER_SYSTEM_PROMPT_SUMMARIZER
        user_prompt = RESEARCHER_USER_TEMPLATE_SUMMARIZER.format(
            description=description,
            context_str=context_str
        )
        try:
            response = llm.invoke([
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ])
            summary = strip_thinking_tokens(response.content)
            
        except Exception as e:
            logger.error(f"Summarization failed: {e}")
            summary = "Failed to generate summary, but raw findings are saved."

    # --- 3. æ„é€ æ›´æ–°åçš„ Plan å’Œ æ›´æ–°ç¬”è®° ---
    # æ ‡è®°å½“å‰æ­¥éª¤ä¸º "completed"ï¼Œå¹¶æŠŠç»“æœå¡«è¿›å»
    note_tool = NoteTool()
    
    updated_plan = []
    for i, step in enumerate(plan):
        if i == current_index:
            updated_step = {
                **step,
                "status": "completed",
                "result": summary
            }
            
            # [é›†æˆ NoteTool] æ›´æ–°ç¬”è®°å†…å®¹
            note_id = step.get("note_id")
            if note_id:
                # å°†æ–°å†…å®¹è¿½åŠ åˆ°ç¬”è®°ä¸­
                # å…ˆè¯»å–æ—§å†…å®¹ï¼Ÿæˆ–è€…ç›´æ¥è¦†ç›–ã€‚Summarizer ç”Ÿæˆçš„å†…å®¹é€šå¸¸æ˜¯å®Œæ•´çš„ markdown ç¬”è®°ã€‚
                # ä½†ä¸ºäº†ä¿ç•™ä¹‹å‰çš„ metadataï¼Œæˆ‘ä»¬ç”¨ updateã€‚
                logger.info(f"Updating Note {note_id} with research findings...")
                note_tool._run(
                    action="update",
                    note_id=note_id,
                    content=summary, # ç”¨ç”Ÿæˆçš„æ‘˜è¦è¦†ç›–å†…å®¹
                    tags=["completed", "research"]
                )
            else:
                logger.warning(f"Warning: No Note ID found for step {i+1}")

            updated_plan.append(updated_step)
        else:
            updated_plan.append(step)

    # --- 4. è¿”å› State ---
    
    # [ä¼˜åŒ–] ä¸º raw_data_context æ·»åŠ æ ‡ç­¾ï¼Œæ–¹ä¾¿ Coder è¯†åˆ«
    tagged_context = []
    if raw_texts:
        # ä½¿ç”¨ Plan Description ä½œä¸º Tagï¼Œè®© Coder çŸ¥é“è¿™æ®µæ•°æ®æ˜¯å¹²å˜›çš„
        tag = f"Data source from step '{description}':\n"
        tagged_context = [tag + context_str]

    return {
        "plan": updated_plan,
        "research_findings": new_findings, # è¿™é‡Œä¼šè‡ªåŠ¨ append (operator.add)
        "current_step_index": current_index + 1, # æŒ‡é’ˆè‡ªåŠ¨åç§»ï¼
        "last_step_success": True,
        # è¿™é‡Œå…¶å®åº”è¯¥æŠŠ summary è¿½åŠ åˆ° running_summaryï¼Œæš‚ä¸”ç®€åŒ–å¤„ç†
        "raw_data_context": tagged_context # append to list
    }
